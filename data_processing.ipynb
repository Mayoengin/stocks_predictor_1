{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Define the stock symbols and data directory\n",
    "stock_symbols = ['AAPL', 'GOOGL', 'MSFT']\n",
    "data_dir = 'data'\n",
    "\n",
    "# Initialize a dictionary to store processed data\n",
    "processed_data = {}\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data for AAPL\n",
      "Processed data for GOOGL\n",
      "Processed data for MSFT\n"
     ]
    }
   ],
   "source": [
    "for symbol in stock_symbols:\n",
    "    file_path = os.path.join(data_dir, f'{symbol}_data.csv')\n",
    "    \n",
    "    if not os.path.exists(file_path):\n",
    "        print(f\"Data for {symbol} not found at {file_path}\")\n",
    "        continue\n",
    "    \n",
    "    # Load the dataset\n",
    "    df = pd.read_csv(file_path, index_col='Date', parse_dates=True)\n",
    "    \n",
    "    # Example data processing steps\n",
    "    # Drop rows with missing values\n",
    "    df = df.dropna()\n",
    "    \n",
    "    # Scale the data\n",
    "    df_scaled = scaler.fit_transform(df)\n",
    "    \n",
    "    # Convert back to DataFrame\n",
    "    df_scaled = pd.DataFrame(df_scaled, index=df.index, columns=df.columns)\n",
    "    \n",
    "    # Store the processed data\n",
    "    processed_data[symbol] = df_scaled\n",
    "    print(f\"Processed data for {symbol}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data for AAPL:\n",
      "                Open      High       Low     Close  Adj Close    Volume\n",
      "Date                                                                   \n",
      "2020-01-02  0.126588  0.131229  0.149485  0.137767   0.132509  0.256276\n",
      "2020-01-03  0.128278  0.131193  0.151856  0.132473   0.127380  0.283984\n",
      "2020-01-06  0.122038  0.130064  0.145068  0.136770   0.131543  0.212595\n",
      "2020-01-07  0.133274  0.131775  0.153630  0.134213   0.129066  0.188279\n",
      "2020-01-08  0.128297  0.138218  0.153051  0.142917   0.137497  0.247584\n",
      "\n",
      "Processed data for GOOGL:\n",
      "                Open      High       Low     Close  Adj Close    Volume\n",
      "Date                                                                   \n",
      "2020-01-02  0.148347  0.153649  0.171458  0.161919   0.161919  0.157751\n",
      "2020-01-03  0.148139  0.156231  0.171880  0.158233   0.158233  0.123771\n",
      "2020-01-06  0.149982  0.168741  0.173749  0.176914   0.176914  0.328885\n",
      "2020-01-07  0.174787  0.171378  0.194347  0.175524   0.175524  0.219672\n",
      "2020-01-08  0.171922  0.175630  0.194890  0.180636   0.180636  0.228312\n",
      "\n",
      "Processed data for MSFT:\n",
      "                Open      High       Low     Close  Adj Close    Volume\n",
      "Date                                                                   \n",
      "2020-01-02  0.101582  0.095590  0.123092  0.118488   0.110872  0.152841\n",
      "2020-01-03  0.099435  0.091892  0.121805  0.109084   0.101942  0.135692\n",
      "2020-01-06  0.093649  0.087862  0.114412  0.111012   0.103773  0.132247\n",
      "2020-01-07  0.104102  0.090564  0.118275  0.104194   0.097298  0.141590\n",
      "2020-01-08  0.102282  0.095922  0.121280  0.115996   0.108506  0.211198\n",
      "\n",
      "Processed data for AAPL saved to data\\AAPL_processed_data.csv\n",
      "Processed data for GOOGL saved to data\\GOOGL_processed_data.csv\n",
      "Processed data for MSFT saved to data\\MSFT_processed_data.csv\n"
     ]
    }
   ],
   "source": [
    "# Example of using the processed data\n",
    "for symbol, data in processed_data.items():\n",
    "    print(f\"Processed data for {symbol}:\\n{data.head()}\\n\")\n",
    "\n",
    "# Optionally, save the processed data to CSV files\n",
    "for symbol, data in processed_data.items():\n",
    "    processed_file_path = os.path.join(data_dir, f'{symbol}_processed_data.csv')\n",
    "    data.to_csv(processed_file_path)\n",
    "    print(f\"Processed data for {symbol} saved to {processed_file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
